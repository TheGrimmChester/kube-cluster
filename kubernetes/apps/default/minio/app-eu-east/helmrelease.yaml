---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: minio-eu-east
  namespace: default
spec:
  interval: 30m
  chart:
    spec:
      chart: app-template
      version: 1.5.1
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    controller:
      annotations:
        reloader.stakater.com/auto: "true"
    image:
      repository: quay.io/minio/minio
      tag: RELEASE.2023-08-09T23-30-22Z
    env:
      TZ: Europe/Paris
      MINIO_UPDATE: "off"
      MINIO_PROMETHEUS_URL: http://kube-prometheus-stack-prometheus.monitoring.svc.cluster.local:9090
      MINIO_PROMETHEUS_JOB_ID: minio
      MINIO_BROWSER_REDIRECT_URL: "https://minio-eu-east.${SECRET_DOMAIN}"
      MINIO_SERVER_URL: "https://s3-eu-east.${SECRET_DOMAIN}"
      MINIO_API_CORS_ALLOW_ORIGIN: "https://minio-eu-east.${SECRET_DOMAIN},https://s3.${SECRET_DOMAIN}"
    envFrom:
      - secretRef:
          name: minio-secret
    args: ["server", "/data", "--console-address", ":9001"]
    service:
      main:
        enabled: true
        ports:
          http:
            port: &console-port 9001
          api:
            enabled: true
            port: &api-port 9000
    serviceMonitor:
      main:
        enabled: true
        endpoints:
          - port: api
            scheme: http
            path: /minio/v2/metrics/cluster
            interval: 1m
            scrapeTimeout: 10s
            bearerTokenSecret:
              name: minio-secret
              key: MINIO_PROMETHEUS_TOKEN
    probes:
      liveness: &probes
        enabled: true
        custom: true
        spec:
          httpGet:
            path: /minio/health/live
            port: *api-port
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 1
          failureThreshold: 3
      readiness: *probes
      startup:
        enabled: false
    ingress:
      main:
        enabled: true
        ingressClassName: external
        annotations:
          external-dns.alpha.kubernetes.io/target: "external.${SECRET_DOMAIN}"
#          nginx.ingress.kubernetes.io/whitelist-source-range: "10.0.0.0/8,172.16.0.0/12,192.168.0.0/16"
        hosts:
          - host: &console-host "{{ .Release.Name }}.${SECRET_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
                service:
                  port: *console-port
        tls:
          - hosts:
              - *console-host
      s3:
        enabled: true
        ingressClassName: external
        annotations:
#          nginx.ingress.kubernetes.io/whitelist-source-range: "10.0.0.0/8,172.16.0.0/12,192.168.0.0/16"
          external-dns.alpha.kubernetes.io/target: "external.${SECRET_DOMAIN}"
          nginx.ingress.kubernetes.io/proxy-connect-timeout: "180"
          nginx.ingress.kubernetes.io/proxy-body-size: 1024m
          nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
          nginx.ingress.kubernetes.io/configuration-snippet: |
            chunked_transfer_encoding off;
        hosts:
          - host: &api-host "s3-eu-east.${SECRET_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
                service:
                  port: *api-port
        tls:
          - hosts:
              - *api-host
    podSecurityContext:
      runAsUser: 997
      runAsGroup: 998
      fsGroup: 998
      fsGroupChangePolicy: OnRootMismatch
      supplementalGroups: [100]
    persistence:
      config:
        enabled: true
        type: hostPath
        hostPath: /mnt/ssd_1to/minio
        mountPath: /data
    resources:
      requests:
        memory: 100Mi
        cpu: 100m
      limits:
        memory: 750Mi
    nodeSelector:
      kubernetes.io/hostname: "vm-3"
